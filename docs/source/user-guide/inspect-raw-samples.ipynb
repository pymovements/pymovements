{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Working with Raw Gaze Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "The term \"raw gaze\" or \"raw eye-tracking data\" is used inconsistently in the literature and can refer to different levels of data, depending on context. Common usages include:\n",
    "\n",
    "- **Raw eye-tracker files**: May contain samples, events, messages, and metadata mixed together.\n",
    "- **Raw samples**: Gaze coordinates over time without filtering or event classification.\n",
    "- **Vendor-labeled events**: Fixations or saccades produced by proprietary software.\n",
    "\n",
    "In pymovements, raw samples refer to the lowest-level gaze data available after import, before any additional preprocessing steps, such as smoothing, velocity computation, or event detection. These raw samples form the foundation for all subsequent analyses. Later transformations, e.g. converting pixel coordinates to degrees of visual angle, computing velocities, or segmenting fixations and saccades, operate on these samples and depend on the assumptions and metadata established during\n",
    "loading.\n",
    "\n",
    "The table below shows a simplified example of raw gaze samples after import. Each row corresponds to one time-ordered gaze sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymovements as pm\n",
    "\n",
    "gaze = pm.gaze.io.from_csv(\"../examples/gaze.csv\")\n",
    "gaze.samples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Column dtypes after import:\n",
    "\n",
    "- ``time`` (``i64``) is the timestamp of the sample, typically in milliseconds.\n",
    "- ``pupil`` (``f64``) is an estimate of pupil size (arbitrary units, device-dependent)\n",
    "- ``pixel`` (``list[f64]``) contains the horizontal and vertical gaze coordinates on the display."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Inspecting Raw Samples with Time-Series Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Time-series plots are often the first step when working with newly loaded gaze data. They provide a direct view of the temporal structure of the signal and help assess data quality before any preprocessing or event detection is applied.\n",
    "\n",
    "The :func:`~pymovements.plotting.traceplot` function visualizes raw gaze samples from a\n",
    ":class:`~pymovements.gaze.gaze.Gaze` object as signals over time, allowing inspection of gaze position, pupil size, or derived quantities such as velocity.\n",
    "\n",
    "Time-series inspection can reveal common issues such as signal loss, noise, blinks, sampling irregularities, or calibration problems, which may strongly influence subsequent analysis steps.\n",
    "\n",
    "See the :doc:`Plotting Gaze Data tutorial <../tutorials/plotting>` for an example of time-series visualization using ``traceplot``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Converting Units to Standardized Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Raw gaze samples form the basis of all subsequent analysis, but meaningful interpretation often requires transforming these samples into alternative representations. These transformations operate directly on raw samples and typically precede any event detection or higher-level segmentation.\n",
    "\n",
    "### From Pixels to Degrees of Visual Angle\n",
    "\n",
    "Pixel coordinates depend on screen resolution, viewing distance, and physical screen size. To compare gaze behaviour across setups or participants, it is often useful to convert pixels to degrees of visual angle (dva). This conversion requires knowledge of the experimental geometry and is handled explicitly in pymovements by the :func:`~pymovements.gaze.transforms.pix2deg` function.\n",
    "\n",
    "### From Position to Velocity\n",
    "\n",
    "Many eye-movement measures are derived not from position directly but from its temporal\n",
    "derivatives. Velocity is computed from changes in gaze position over time and is central to event detection algorithms for saccades and fixations. In pymovements, velocity is computed explicitly from position data with the :func:`~pymovements.gaze.transforms.pos2vel` function, using the sampling rate stored in the eye tracker definition.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
