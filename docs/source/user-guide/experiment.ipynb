{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "221eb218",
   "metadata": {},
   "source": [
    "# Experiment Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc670de",
   "metadata": {},
   "source": [
    "The information about the experimental setup in which the eye-tracking data was collected plays a crucial role in its processing. Screen size, viewing distance, coordinate origin, and sampling rate all determine how pixel\n",
    "positions translate into physical or visual units. In `pymovements`, this contextual information is stored in an {py:class}`~pymovements.Experiment` object, which describes the **geometry and timing of the recording setup**. \n",
    "\n",
    "Providing an experiment is not strictly required to load gaze data: samples can still be inspected in raw pixel coordinates and timestamps without it (see {doc}`Inspecting Raw Samples with Plots <inspect-raw-samples>`). However, the experiment definition becomes essential as soon as gaze samples are interpreted in physical or visual terms, for instance, converting pixels to degrees of visual angle or computing velocities (see {doc}`Transforming Raw Samples <inspect-raw-samples>`). These conversions are necessary for detecting oculomotor events such as fixations and saccades (see {doc}`Detecting Occumotoric Events <event-detection>`).\n",
    "\n",
    "The {py:class}`~pymovements.Experiment` object has two main components: {py:class}`~pymovements.Screen` and an {py:class}`~pymovements.EyeTracker`. These can be first defined explicitly and then combined to form an ``Experiment``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d42e64",
   "metadata": {},
   "source": [
    "## Screen\n",
    "\n",
    "The {py:class}`~pymovements.Screen` class describes the physical and pixel properties of the display used during recording. These parameters determine how gaze positions in pixels map to real-world or visual-angle units. They include:\n",
    "\n",
    "- screen resolution in pixels (`width_px`, `height_px`)\n",
    "- physical screen size in centimeters (`width_cm`, `height_cm`)\n",
    "- eye-to-screen distance (`distance_cm`)\n",
    "- coordinate origin (e.g., `\"upper left\"` or `\"center\"`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be96ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymovements as pm\n",
    "from pymovements import Experiment\n",
    "\n",
    "screen = pm.Screen(\n",
    "    width_px=1920,\n",
    "    height_px=1080,\n",
    "    width_cm=53.0,\n",
    "    height_cm=30.0,\n",
    "    distance_cm=65.0,\n",
    "    origin=\"upper left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de7ac0a",
   "metadata": {},
   "source": [
    "If all physical parameters (`width_cm`, `height_cm`, `distance_cm`) and pixel resolution are provided, screen coordinates can be converted from pixels to degrees of visual angle (dva, °). The screen boundaries in dva are available via the properties `x_min_dva`, `x_max_dva`, `y_min_dva`, and `y_max_dva`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1573f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(screen.x_max_dva)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a6faf1",
   "metadata": {},
   "source": [
    "### Variable Viewing Distance\n",
    "\n",
    "In many laboratory setups, the eye-to-screen distance is constant and can be specified once via `distance_cm` in the experiment definition. However, in some recordings, for example in head-free or mobile eye-tracking setups, the distance between the eye and the screen may vary over time. In such cases, the viewing distance can be provided per sample as a column in the {py:class}`~pymovements.Gaze` data instead of as a fixed value in the experiment. The eye-to-screen distance is required for converting pixel coordinates into degrees of visual angle (dva). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e8bea9",
   "metadata": {},
   "source": [
    "### Coordinate Origin\n",
    "\n",
    "The `origin` parameter defines where pixel coordinate (0, 0) is located on the screen. This choice affects how gaze positions are interpreted and transformed. The origin should match the coordinate system used during stimulus presentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a885c91",
   "metadata": {},
   "source": [
    "## Eye Tracker\n",
    "\n",
    "The {py:class}`~pymovements.EyeTracker` class stores temporal and device-specific properties of the eye tracker model. It contains:\n",
    "\n",
    "- sampling rate in Hz\n",
    "- which eye(s) were recorded\n",
    "- optional metadata about the device\n",
    "\n",
    "The sampling rate is especially important for time-based computations such as velocity estimation and event detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a216c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eyetracker = pm.EyeTracker(\n",
    "    sampling_rate=1000.0,\n",
    "    model=\"EyeLink 1000 Plus\",\n",
    "    left=False,\n",
    "    right=True,\n",
    "    version=\"2.0\",\n",
    "    vendor=\"EyeLink\",\n",
    "    mount=\"Arm Mount / Monocular / Remote\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f01bc10",
   "metadata": {},
   "source": [
    "### Sampling Rate\n",
    "\n",
    "The sampling rate determines the temporal resolution of the recording and is stored in the eye tracker component of the experiment. Typically reported in hertz (Hz), it specifies how many gaze samples are recorded per second. Values range from around 30 Hz for low-cost or webcam-based systems to 500 Hz or 2000 Hz for high-end research-grade eye trackers.\n",
    "\n",
    "In general, higher sampling rates allow finer temporal detail to be captured. The Nyquist–Shannon sampling theorem states that a signal must be sampled at least twice as fast as its highest frequency component to avoid aliasing. In practice, this means that high sampling rates are required to capture rapid eye movements such as saccades, while lower sampling rates may be sufficient for analyses focused on fixations or overall viewing patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c554bbd6",
   "metadata": {},
   "source": [
    "## Creating an Experiment\n",
    "\n",
    "Now the initialized {py:class}`~pymovements.Screen` and {py:class}`~pymovements.EyeTracker` objects can be passed directly to the {py:class}`~pymovements.Experiment` constructor using the ``screen`` and ``eyetracker`` parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c59b96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = pm.Experiment(screen=screen, eyetracker=eyetracker)\n",
    "\n",
    "print(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145b5e99",
   "metadata": {},
   "source": [
    "Alternatively, an `Experiment` can be created directly by passing the required screen and eye tracker parameters to the constructor. In this case, the corresponding `Screen` and `EyeTracker` objects are initialized internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec1f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_experiment = Experiment(\n",
    "    screen_width_px=1280,\n",
    "    screen_height_px=1024,\n",
    "    screen_width_cm=38.0,\n",
    "    screen_height_cm=30.0,\n",
    "    distance_cm=68.0,\n",
    "    origin=\"upper left\",\n",
    "    sampling_rate=1000.0,\n",
    ")\n",
    "\n",
    "print(example_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d108d199",
   "metadata": {},
   "source": [
    "All discussed parameters can be accessed directly as attributes of the `Experiment` instance. For example, the sampling rate can be accessed and printed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe85ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(experiment.sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e638f906",
   "metadata": {},
   "source": [
    "## Loading Experiment from a Dictionary\n",
    "\n",
    "Experiments can also be constructed from dictionaries, which is useful when\n",
    "reading metadata from configuration files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ddd462",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment.from_dict({\n",
    "    \"screen\": {\n",
    "        \"width_px\": 1280,\n",
    "        \"height_px\": 1024,\n",
    "        \"width_cm\": 38.0,\n",
    "        \"height_cm\": 30.0,\n",
    "        \"distance_cm\": 68.0,\n",
    "        \"origin\": \"upper left\",\n",
    "    },\n",
    "    \"eyetracker\": {\n",
    "        \"sampling_rate\": 1000.0,\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df51276",
   "metadata": {},
   "source": [
    "## Saving Experiment Settings\n",
    "\n",
    "Experiment configurations can be exported to a dictionary or `YAML` file for\n",
    "reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b04dffe",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "experiment_dict = experiment.to_dict()\n",
    "experiment.to_yaml(\"experiment.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a233b80c",
   "metadata": {},
   "source": [
    "\n",
    "This makes it easy to store the recording setup alongside your data and reuse it in later analyses.\n",
    "\n",
    "In the next section, we will use this experiment definition while loading gaze data and explore how raw samples are represented inside `pymovements`.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
